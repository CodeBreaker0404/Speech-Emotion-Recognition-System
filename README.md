# Speech Emotion REcognition System

This project contains an Emotion Recognition System and it leverages deep learning to classify emotions using audio spectral features like MFCCs, mel spectrograms, chromagrams, and spectral contrast, enabling accurate emotional analysis from speech inputs.

## Dataset
In this project we're finding the emotion of a person by its vocal pattern. To achive this we are training our model with numerous dataset which contain voices of different actors. These are dataset we have:-
* CREMA-D ( Crowd-sourced Emotional Mutimodal Actors Dataset )
  https://www.kaggle.com/datasets/ejlok1/cremad
* RAVDESS ( Ryerson Audio-Visual Database of Emotional Speech and Song  )
    https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio
* SAVEE( Surrey Audio-Visual Expressed Emotion )
  https://www.kaggle.com/datasets/ejlok1/surrey-audiovisual-expressed-emotion-savee
* TESS( Toronto emotional speech set )
  https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess



## Authors

- [@CodeBreaker044](https://www.github.com/CodeBreaker044)
- [@adithya-santhosh](https://www.github.com/adithya-santhosh)





## Tech Stack

Tensorflow, Pytorch, Sklearn

